from typing import List

from exaflow import exareme3_algorithm_classes
from exaflow.aggregation_clients import aggregation_server_pb2 as agg_pb2
from exaflow.aggregation_clients.controller_aggregation_client import (
    ControllerAggregationClient,
)
from exaflow.algorithms.exareme3.longitudinal_transformer import (
    prepare_longitudinal_transformation,
)
from exaflow.algorithms.utils.inputdata_utils import Inputdata
from exaflow.controller import config as controller_config
from exaflow.controller.federation_info_logs import log_experiment_execution
from exaflow.controller.services.exareme3 import ExaflowController
from exaflow.controller.services.exareme3.algorithm_flow_engine_interface import (
    ExaflowAlgorithmFlowEngineInterface,
)
from exaflow.controller.services.exareme3.tasks_handler import ExaflowTasksHandler
from exaflow.controller.services.strategy_interface import AlgorithmExecutionStrategyI


class ExaflowStrategy(AlgorithmExecutionStrategyI):
    _controller: ExaflowController
    _local_worker_tasks_handlers: List[ExaflowTasksHandler]
    _global_worker_tasks_handler: ExaflowTasksHandler

    async def execute(self) -> str:
        raw_inputdata = Inputdata.parse_raw(
            self._algorithm_request_dto.inputdata.json()
        )
        variable_names = (raw_inputdata.x or []) + (raw_inputdata.y or [])
        metadata = self._controller.worker_landscape_aggregator.get_metadata(
            data_model=raw_inputdata.data_model,
            variable_names=variable_names,
        )

        preprocessing = self._algorithm_request_dto.preprocessing or {}
        preprocessing_payload = None
        if "longitudinal_transformer" in preprocessing:
            prep_payload = None
            (
                transformed_inputdata,
                metadata,
                prep_payload,
            ) = prepare_longitudinal_transformation(
                raw_inputdata, metadata, preprocessing["longitudinal_transformer"]
            )
            preprocessing_payload = {"longitudinal_transformer": prep_payload}
        else:
            transformed_inputdata = raw_inputdata

        engine = ExaflowAlgorithmFlowEngineInterface(
            request_id=self._request_id,
            context_id=self._context_id,
            tasks_handlers=self._local_worker_tasks_handlers,
            preprocessing=preprocessing_payload,
            raw_inputdata=raw_inputdata,
        )
        algorithm_cls = exareme3_algorithm_classes[self._algorithm_name]
        algorithm = algorithm_cls(
            inputdata=transformed_inputdata,
            engine=engine,
            parameters=self._algorithm_request_dto.parameters,
        )
        log_experiment_execution(
            self._logger,
            self._request_id,
            self._context_id,
            self._algorithm_name,
            transformed_inputdata.datasets,
            self._algorithm_request_dto.parameters,
            [h.worker_id for h in self._local_worker_tasks_handlers],
        )
        result = algorithm.run(metadata)
        self._logger.info(
            f"Execution completed: {self._algorithm_name} ({self._request_id})"
        )
        return result.json()


class ExaflowWithAggregationServerStrategy(ExaflowStrategy):
    async def execute(self) -> str:

        agg_dns = (
            getattr(getattr(controller_config, "aggregation_server", {}), "dns", None)
            or None
        )
        agg_client = ControllerAggregationClient(
            self._request_id, aggregator_dns=agg_dns
        )
        status = agg_client.configure(
            num_workers=len(self._local_worker_tasks_handlers)
        )
        if status != agg_pb2.Status.OK:
            raise RuntimeError(f"AggregationServer refused to configure: {status}")
        self._logger.debug(f"Aggregation configured: {status}")

        try:
            return await super().execute()
        finally:
            cleanup_status = agg_client.cleanup()
            self._logger.debug(f"Aggregation cleanup response: {cleanup_status}")
